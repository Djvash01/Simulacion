{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2 - Parte 1\n",
    "\n",
    "### Modelos no paramétricos\n",
    "\n",
    "### Regresi&oacute;n con K-Nearest-Neighbors & Ventana de Parzen\n",
    "\n",
    "### Universidad de Antioquia\n",
    "\n",
    "### Facultad de Ingeniería\n",
    "\n",
    "### Ingeniería de Sistemas\n",
    "\n",
    "### Ude@ - 2018-I\n",
    "\n",
    "#### Profesor: Antonio Tamayo Herrera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes:\n",
    "\n",
    "#### Nombre: David de Jesus Yepes Isaza\n",
    "#### Cédula: 1020455542\n",
    "\n",
    "#### Nombre: Rodrigo Antonio Porras Martinez\n",
    "#### Cédula: 1039459720\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En esta archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Genere un conjunto de 1000 muestras artificiales con una distribución que corresponda a la suma de dos Gaussiana con diferente media, ambas de una sola dimension. Grafique el histograma de los datos generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xea151f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "\n",
    "#Complete el código para el ejercicio 1 aquí\n",
    "mu1, sigma1 = 4, 2 # media y desviacion estandar\n",
    "mu2, sigma2 = 13, 2\n",
    "\n",
    "#Preguntar al profe si es que el total de muestras o sumar cada dato\n",
    "datos1=np.random.normal(mu1, sigma1,1000)\n",
    "datos2=np.random.normal(mu2, sigma2,1000)\n",
    "total= datos1 + datos2\n",
    "plt.hist(total,30,(0,30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "A continuación se define el método dist_euclidiana. En la parte del código dónde está el comentario \"completar\" debe escribir el código que permita calcular la salida de dicha función. Es decir, lleve a código la siguiente función:\n",
    "\n",
    "$$ d(x, x^*) = \\sqrt{(x_1-x_{1}^{*})^2+(x_2-x_{2}^{*})^2+...+(x_{n-1}-x_{n-1}^{*})^2+(x_n-x_{n}^{*})^2} $$\n",
    "\n",
    "Nota: Consulte la librería scipy y si lo ve conveniente use los métodos que le puedan ayudar para resolver el laboratorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "#Método para calcular la distancia entre dos vectores\n",
    "def dist_euclidiana(x1, x2):\n",
    "    #Complete el código para calcular la distancia entre x1 y x2\n",
    "    dist = np.sqrt(sum([(a - b)**2 for a, b in zip(x1, x2)]))\n",
    "    #dist = distance.euclidean(x1,x2)\n",
    "    \n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Analice los siguientes métodos a la luz de la teoría vista para los modelos de K vecinos más cercanos (KNN) y ventana de Parzen. Una vez comprenda su funcionamiento proceda a completar el código del método KNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import operator\n",
    "\n",
    "#Error cuadrático medio para los problemas de regresión\n",
    "def ECM(Y_est,Y):\n",
    "    N = np.size(Y)\n",
    "    Y = 100*Y\n",
    "    Y_est = 100*np.asarray(Y_est)\n",
    "    ecm = sum((Y_est - Y)**2)/(2*N)\n",
    "    \n",
    "    return ecm\n",
    "\n",
    "#Para calcular el error en los problemas de clasificación\n",
    "def error(Y_lest, Y):\n",
    "    error = 0\n",
    "    for ye, y in zip(Y_lest, Y):\n",
    "        if ye != y:\n",
    "            error += 1\n",
    "    \n",
    "    error = error/np.size(Y)\n",
    "    \n",
    "    return error\n",
    "\n",
    "\n",
    "def KNN(X_train, Y_train, X_val, Y_val, knn, tipo):\n",
    "    \n",
    "    k = knn    #Parámetro k que equivale al número de vecinos a tener en cuenta para resolver el problema de\n",
    "               #predicción de la variable de salida\n",
    "    \n",
    "    Y_est = []\n",
    "    \n",
    "    for x1 in X_val:\n",
    "        distances = dict()    #Estudien la estrucutra de datos diccionario de Python para que comprendan el codigo\n",
    "        for x2, y2 in zip(X_train, Y_train):\n",
    "            distances.update({dist_euclidiana(x1,x2): y2})\n",
    "    \n",
    "        #k vecinos más cercanos cercanos\n",
    "        vecinos = sorted(distances.items(), key=operator.itemgetter(0))\n",
    "        #print (vecinos)\n",
    "        #print (type(vecinos))\n",
    "        #print(np.shape(vecinos))\n",
    "        \n",
    "        \n",
    "        #Complete aquí el código para tomar solo la variables de salida de los k vecinos más cercanos\n",
    "        y_vecinos = []\n",
    "        for v in vecinos[:knn]:\n",
    "            y_vecinos.append(v[1])\n",
    "        #Se calcula la variable de salida\n",
    "        #Regression\n",
    "        if tipo == 'regression':\n",
    "            #Complete el código aquí para calcular la variable de salida en el problema de regresión\n",
    "            y_est = np.mean(y_vecinos)\n",
    "            Y_est.append(y_est)\n",
    "        #Classification\n",
    "        elif tipo == 'classification':\n",
    "            #Complete el código aquí para calcular la variable de salida en el problema de clasificación\n",
    "            #y_est = \n",
    "            Y_est.append(y_est)\n",
    "    \n",
    "    if tipo == 'regression':\n",
    "        print (\"Modelo KNN para regresión\\n\\n\"+\"El Error cuadrático medio del modelo con \" + str(k) + \" vecinos es = \" +  str(ECM(Y_est,Y_val)))\n",
    "    elif tipo == 'classification':\n",
    "        print (\"Modelo KNN para clasificación\\n\\n\"+\"El Error de clasificación del modelo con \" + str(k) + \" vecinos es = \" + '''Complete el codigo para mostrar el error''')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "A continuación se leen los datos de un problema de regresión. Las variables o caracterísicas son guardadas en la variable X que posteriormente es normalizada y la variable de salida o variable a predecir es guardada en la variable Y. Note que la base de datos de entrenamiento se parte, de manera aleatoria, en una parte con las muestras para entrenamiento y otra parte con las muestras para validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 12)\n",
      "Modelo KNN para regresión\n",
      "\n",
      "El Error cuadrático medio del modelo con 3 vecinos es = 15.410802490421473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#cargamos la bd que está en un archivo .data y ahora la podemos manejar de forma matricial\n",
    "db = np.loadtxt('DB/AirQuality.data',delimiter='\\t')  # Assuming tab-delimiter\n",
    "\n",
    "#Esta es la base de datos AirQuality del UCI Machine Learning Repository \n",
    "#https://archive.ics.uci.edu/ml/datasets/Air+Quality#\n",
    "\n",
    "#Carga la base de datos completa.\n",
    "#X = db[:,0:12]\n",
    "#Y = db[:,12]\n",
    "\n",
    "#Carga solo las 100 primeras observaciones muestrales de la base de datos\n",
    "X = db[0:100,0:12]\n",
    "Y = db[0:100,12]\n",
    "#print(Y)\n",
    "\n",
    "#Normalizamos los datos\n",
    "X = normalize(X, axis=0, norm='l1')\n",
    "\n",
    "#Partición de la base de datos\n",
    "Nsample = np.size(X,0);\n",
    "indices = np.random.permutation(Nsample);\n",
    "\n",
    "#Conjunto de muestras de entrenamiento\n",
    "Xtrain = X[indices[1:round(0.7*Nsample)],:]\n",
    "Ytrain = Y[indices[1:round(0.7*Nsample)]]\n",
    "\n",
    "#Conjunto de muestras de validación\n",
    "Xtest = X[indices[round(0.7*Nsample)+1:Nsample],:]\n",
    "Ytest = Y[indices[round(0.7*Nsample)+1:Nsample]]\n",
    "print(np.shape(Xtest))\n",
    "\n",
    "#Complete el código llamando el método KNN con sus respectivos argumentos para el problema de regresión\n",
    "#En el ejercicios 5 se le pide variar el valor de k y analizar.\n",
    "k=3\n",
    "tipo=\"regression\"\n",
    "KNN(Xtrain,Ytrain,Xtest,Ytest,k,tipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Describa la base de datos de entrenamiento. Diga cu&aacute;ntas muestras tiene en total y cu&aacute;ntas caracter&iacute;sticas.\n",
    "\n",
    "4.2 Qu&eacute; porcentaje de la base de datos se usa para el entrenamiento del modelo? A cu&aacute;ntas muestras corresponde esto? Cu&aacute;ntas muestras se usan para la validaci&oacute;n?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda Aqu&iacute;:\n",
    "\n",
    "4.1 R/: Contiene las respuestas de un dispositivo multisensor de gas desplegado en el campo en una ciudad italiana. Los promedios de las respuestas horarias se registran junto con las referencias de concentraciones de gases de un analizador certificado. Xtrain tiene 70 muestras y 12 caracteriscas, Ytrain tiene la misma cantidad de muestras y el y teorico\n",
    "\n",
    "4.2 R/: Si hablamos de la base de datos original que tiene 9358 muestras, el porcentaje usado es de 0.74% que equivale 70 muestras aproximandamente. Ahora bien, de la db que se usa para el ejercicio se usan 70 muestras que son el 70% y 30%  para la validacion, siendo respectivamente 30 muestras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo KNN para regresión\n",
      "\n",
      "El Error cuadrático medio del modelo con 1 vecinos es = 51.82335862068967\n",
      "Modelo KNN para regresión\n",
      "\n",
      "El Error cuadrático medio del modelo con 2 vecinos es = 20.5929077586207\n",
      "Modelo KNN para regresión\n",
      "\n",
      "El Error cuadrático medio del modelo con 3 vecinos es = 15.410802490421473\n",
      "Modelo KNN para regresión\n",
      "\n",
      "El Error cuadrático medio del modelo con 4 vecinos es = 16.336391594827596\n",
      "Modelo KNN para regresión\n",
      "\n",
      "El Error cuadrático medio del modelo con 5 vecinos es = 13.52037731034484\n",
      "Modelo KNN para regresión\n",
      "\n",
      "El Error cuadrático medio del modelo con 6 vecinos es = 15.351063984674326\n",
      "Modelo KNN para regresión\n",
      "\n",
      "El Error cuadrático medio del modelo con 7 vecinos es = 15.574026073187905\n"
     ]
    }
   ],
   "source": [
    "#Complete el código llamando el método KNN con sus respectivos argumentos para el problema de regresión\n",
    "#En el ejercicios 5 se le pide variar el valor de k y analizar.\n",
    "\n",
    "\n",
    "tipo=\"regression\"\n",
    "for k in range(1,8):\n",
    "    KNN(Xtrain,Ytrain,Xtest,Ytest,k,tipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Identifique la variable k (número de vecinos más cercanos definido para el modelo $k$) en el método KNN. En la celda de c&oacute;digo anterior, llame al método KNN cambiando el valor de $k$ de acuerdo a la siguiente tabla y complete la columna ECM.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>K (número de vecinos)</th>\n",
    "    <th>Error Cuadrático Medio (ECM)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>30.570884482758615</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>22.191366379310338</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>24.577922413793093</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>23.391978124999998</td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #b9f6ca;\">\n",
    "    <td>5</td>\n",
    "    <td>19.36591131034484</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>20.242934961685812</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td>20.21437751583392</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Vaya al código de la celda donde se hace la carga de la base de datos y cargue la base de datos completa. Vuelva a correr el algorítmo.\n",
    "\n",
    "5.1 Qué sucede? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda aquí:\n",
    "    \n",
    "5.1 R/: No ejecuta el algoritmo o se tarda mucho en maquinas de mejor procesador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Por qué ocurre eso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda aquí:\n",
    "    \n",
    "5.2 R/: La DB tiene demasiados datos, lo que acarrea un mayor costo de hardware. El costo actual supera la capacidad del procesador del PC local, por esta razón el algoritmo no retorna valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 El modelo es viable para resolver este problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda aquí:\n",
    "    \n",
    "5.3 R/: Dependeria de los requisitos de hardware que tiene el problema, pero para este caso, con hardware de gama baja - media este modelo no es viable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Note qu&eacute; en el c&oacute;digo de la funci&oacute;n que calcula el error cuadr&aacute;tico medio se est&aacute; multiplicando por $100$ cada entrada del vector Y te&oacute;rico y del vector Y estimado. Analice los valores de la variable de salida Y en la base de datos antes de hacer esta modificaci&oacute;n y explique que implicaciones tendr&iacute;a en el ECM el hecho de no realizar dicha modificaci&oacute;n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda aqu&iacute;\n",
    "\n",
    "5.4 R/: Los valores de Y son valores entre el intervalo 1 y 0, Al elevar un numero menor que cero tiende a disminuir. Y un numero muy pequeño divido por uno que es mucho mas grande tiende a cero o ser mas pequeño. Al final la interpretacion del ECM para el analisis se hace muy dificil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "\n",
    "Ahora debe resolver el mismo problema de regresión, pero con el modelo de ventana de Parzen.\n",
    "\n",
    "Para el problema de regresión debe completar el código para implementar la función Nadaraya-Watson.\n",
    "\n",
    "Nota: Los métodos dist_euclidiana y ECM continuan siendo válidos para el modelo ventana de Parzen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_gaussiano(x):\n",
    "    return (1/np.sqrt(2*np.pi))*np.exp((-0.5)*x**2)\n",
    "\n",
    "def Nadaraya_Watson(X_train, Y_train, X_val, Y_val, ancho_h):\n",
    "        \n",
    "    h = ancho_h\n",
    "        \n",
    "    Y_est = []\n",
    "    for x1 in X_val:\n",
    "        y_est = 0\n",
    "        distances = []\n",
    "        for x2 in X_train:\n",
    "            distances.append(dist_euclidiana(x1,x2))\n",
    "        \n",
    "        #Tenga en cuenta que distances es una lista y la puede convertir a un arreglo con el método np.asarray (consulte)\n",
    "        distances = np.asarray(distances)\n",
    "        #Complete el codigo aquí\n",
    "        #implemente la función de Nadaraya-Watson usando el kernel gaussiano   \n",
    "        y_est = sum((kernel_gaussiano(distances/h))*Y_train)/sum(kernel_gaussiano(distances/h))\n",
    "        Y_est.append(y_est)\n",
    "    \n",
    "    print (\"Modelo ventana de Parzen para regresión (Nadaraya-Watson)\\n\\n\"+\"El Error cuadrático medio del modelo con h = \" + str(h) + \" es = \" + str(ECM(Y_est, Y_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7\n",
    "\n",
    "Complete el código llamando al método Nadaraya_Watson, pasándole los parámetros correspondientes. Tenga en cuenta que ya en una celda previa se hizo la lectura de la base de datos AirQuality y se realiz&oacute; la partici&oacute;n correspondiente de la misma para entrenamiento y validaci&oacute;n. Use Xtrain, Ytrain, Xtest y Ytest (ya cargadas en memoria) como par&aacute;metros para el modelo Nadaraya-Watson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo ventana de Parzen para regresión (Nadaraya-Watson)\n",
      "\n",
      "El Error cuadrático medio del modelo con h = 0.015 es = 19.757387113421782\n"
     ]
    }
   ],
   "source": [
    "#Complete la siguiente línea de código llamando el método Nadaraya_Watson con sus respectivos argumentos\n",
    "h=0.015\n",
    "Nadaraya_Watson(Xtrain,Ytrain,Xtest,Ytest,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8\n",
    "\n",
    "Identifique la variable h (ancho de la ventana $h$) en el método Nadaraya_Watson. Llame al método Nadaraya_Watson en la celda anterior, cambiando el valor de $h$ de acuerdo a la siguiente tabla y complete la columna ECM.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>h (ancho de la ventana)</th>\n",
    "    <th>Error Cuadrático Medio (ECM)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.001</td>\n",
    "    <td>42.990824208776544</td>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td>0.01</td>\n",
    "    <td>19.396242375358646</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.1</td>\n",
    "    <td>20.52851286459664</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>20.586351283775436</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>20.587322743728663</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "8.1 Qué sucede cuando $h = 0.001$? Por qué? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda aquí:\n",
    "    \n",
    "8.1 R/: Si $h$ es muy pequeña el peso de la muestras mas lejanas se haces muy pequeño o despreciable y no aportarian a la funcion. Por esta razón el error mas alto esta con $0.001$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
