{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 5 Parte 2\n",
    "\n",
    "### Reducción de dimensión por extracción de características con PCA y LDA\n",
    "\n",
    "### Universidad de Antioquia\n",
    "\n",
    "### Facultad de Ingeniería\n",
    "\n",
    "### Ingeniería de Sistemas\n",
    "\n",
    "### Ude@ - 2018-I\n",
    "\n",
    "#### Profesor: Antonio Tamayo Herrera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudiantes\n",
    "\n",
    "Nombre: Rodrigo Antonio Porras Martinez\n",
    "\n",
    "Céduda: 1039459720\n",
    "\n",
    "Nombre: David Yepes Isaza\n",
    "\n",
    "Cédula: 1020455542"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guía del laboratorio\n",
    "\n",
    "En esta archivo va a encontrar tanto celdas de código cómo celdas de texto con las instrucciones para desarrollar el laboratorio.\n",
    "\n",
    "Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicaciones\n",
    "\n",
    "Este ejercicio tiene como objetivo implementar varias técnicas de extracción de características (PCA y LDA) y usar SVM para resolver un problema de clasificación multietiqueta o multiclase.\n",
    "\n",
    "Para el problema de clasificación usaremos la siguiente base de datos: https://archive.ics.uci.edu/ml/datasets/Cardiotocography\n",
    "\n",
    "#### Abstract: \n",
    "The dataset consists of measurements of fetal heart rate (FHR) and uterine contraction (UC) features on cardiotocograms classified by expert obstetricians.\n",
    "\t\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "LB - FHR baseline (beats per minute)\n",
    "\n",
    "AC - # of accelerations per second\n",
    "\n",
    "FM - # of fetal movements per second\n",
    "\n",
    "UC - # of uterine contractions per second\n",
    "\n",
    "DL - # of light decelerations per second\n",
    "\n",
    "DS - # of severe decelerations per second\n",
    "\n",
    "DP - # of prolongued decelerations per second\n",
    "\n",
    "ASTV - percentage of time with abnormal short term variability\n",
    "\n",
    "MSTV - mean value of short term variability\n",
    "\n",
    "ALTV - percentage of time with abnormal long term variability\n",
    "\n",
    "MLTV - mean value of long term variability\n",
    "\n",
    "Width - width of FHR histogram\n",
    "\n",
    "Min - minimum of FHR histogram\n",
    "\n",
    "Max - Maximum of FHR histogram\n",
    "\n",
    "Nmax - # of histogram peaks\n",
    "\n",
    "Nzeros - # of histogram zeros\n",
    "\n",
    "Mode - histogram mode\n",
    "\n",
    "Mean - histogram mean\n",
    "\n",
    "Median - histogram median\n",
    "\n",
    "Variance - histogram variance\n",
    "\n",
    "Tendency - histogram tendency\n",
    "\n",
    "CLASS - FHR pattern class code (1 to 10)\n",
    "\n",
    "NSP - fetal state class code (N=normal (1); S=suspect (2); P=pathologic (3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analice la base de datos, sus características, su variable de salida y el contexto del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar a ejecutar las celdas, debe instalar la librería mlxtend que usaremos para los laboratorios de reducción de dimensión.\n",
    "Para hacerlo solo tiene que usar el siguiente comando: sudo pip install mlxtend. También puede consultar la guía oficial de instalación\n",
    "    de esta librería: https://rasbt.github.io/mlxtend/installation/\n",
    "\n",
    "Analice y comprenda la siguiente celda de código donde se importan las librerías a usar y se carga la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la base de datos de entrenamiento. dim de X: (2126, 22)\tdim de Y: (2126,)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from mlxtend.preprocessing import standardize\n",
    "from mlxtend.feature_extraction import PrincipalComponentAnalysis as PCA\n",
    "from mlxtend.feature_extraction import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "import time\n",
    "\n",
    "#cargamos la bd de entrenamiento\n",
    "db = np.loadtxt('DB_Fetal_Cardiotocograms.txt',delimiter='\\t')  # Assuming tab-delimiter\n",
    "\n",
    "X = db[:,0:22]\n",
    "\n",
    "#Solo para dar formato a algunas variables\n",
    "for i in range(1,7):\n",
    "    X[:,i] = X[:,i]*1000\n",
    "\n",
    "X = X\n",
    "Y = db[:,22]\n",
    "\n",
    "#Para darle formato de entero a la variable de salida\n",
    "\n",
    "Y_l = []\n",
    "for i in Y:\n",
    "    Y_l.append(int(i))\n",
    "Y = np.asarray(Y_l)\n",
    "\n",
    "print (\"Dimensiones de la base de datos de entrenamiento. dim de X: \" + str(np.shape(X)) + \"\\tdim de Y: \" + str(np.shape(Y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda de código no tiene que completar nada. Analice, comprenda y ejecute el código y tenga en cuenta los resultados para completar la tabla que se le pide más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación sin aplicar extracción: 0.07712817787226504 +/- 0.05442325724156325\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.9090361595153809 segundos.\n"
     ]
    }
   ],
   "source": [
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)\n",
    "\n",
    "#Para calcular el costo computacional\n",
    "tiempo_i = time.time()\n",
    "\n",
    "#Creamos el clasificador SVM. Tenga en cuenta que el problema es multiclase. \n",
    "clf = svm.SVC(decision_function_shape='ovr', kernel='rbf', C = 100, gamma=0.0001)\n",
    "\n",
    "#Implemetamos la metodología de validación\n",
    "\n",
    "Errores = np.ones(10)\n",
    "j = 0\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]  \n",
    "\n",
    "    #Aquí se entran y se valida el modelo sin hacer selección de características\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Entrenamiento el modelo.\n",
    "    model = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Validación del modelo\n",
    "    ypred = model.predict(X_test)\n",
    "    \n",
    "    #######\n",
    "\n",
    "    Errores[j] = classification_error(ypred, y_test)\n",
    "    j+=1\n",
    "\n",
    "print(\"\\nError de validación sin aplicar extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "\n",
    "print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n",
    "\n",
    "#print str(ypred)\n",
    "#print str(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "1.1 Al aplicar PCA es necesario estandarizar los datos? Si, No y por qué? En qué consiste dicha estandarización?\n",
    "\n",
    "R/: En PCA si es neceario estandarizar los datos, consiste en centrar los datos, es decir, para centrar los datos es necesario extraerle la media a las caracteristicas y que la media sea cero. Se debe hacer porque en el tratamiento matricial que sea hace posteriormente necesitan que los datos esten centrados. \n",
    "    \n",
    "1.2 La proyección de los datos que realiza PCA se hace buscando minimizar o maximizar algo? Explique.\n",
    "\n",
    "R/: La proyección de los datos que realiza PCA se hace buscando minimizar las distancias que hay entre el punto $X_i$ y su proyección sobre la dirección del vector unitario $u_1$. De donde se tiene que la distancia es $|x_i-z_j u_1|^2$ y para minimizarla hay que encontrar el vector $u_1$ que maximice $z^2_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "En la siguiente celda, complete el código donde le sea indicado. Consulte la documentación oficial de la librería mlxtend para los métodos de extracción de características. https://rasbt.github.io/mlxtend/user_guide/feature_extraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error de validación aplicando extracción: 0.07430463282841704 +/- 0.04391645244688941\n",
      "\n",
      "Eficiencia en validación aplicando extracción: 92.5695367171583%\n",
      "\n",
      "\n",
      "Tiempo total de ejecución: 0.9602289199829102 segundos.\n"
     ]
    }
   ],
   "source": [
    "#Feature Extraction Function\n",
    "#Recibe 2 parámetros: 1. el tipo de método de extracción (pca o lda como string), 2. el número componentes (para pca)\n",
    "#o el número de discriminantes (para lda)\n",
    "\n",
    "#Para este laboratorio solo se le pedirá trabajar con PCA, LDA es opcional.\n",
    "\n",
    "def extract_features(tipo, n):\n",
    "    \n",
    "    if tipo == 'pca':\n",
    "    \n",
    "        ext = PCA(n_components=n)\n",
    "    \n",
    "        return ext\n",
    "\n",
    "    elif tipo == 'lda':\n",
    "        \n",
    "        ext = LDA(n_discriminants=n)\n",
    "        \n",
    "        return ext\n",
    "    \n",
    "    else:\n",
    "        print (\"Ingrese un método válido (pca o lda)\\n\")\n",
    "\n",
    "#Para calcular el costo computacional\n",
    "tiempo_i = time.time()\n",
    "\n",
    "#Estandarizamos los datos\n",
    "X = standardize(X)\n",
    "\n",
    "#Implemetamos la metodología de validación cross validation con 10 folds\n",
    "\n",
    "Errores = np.ones(10)\n",
    "j = 0\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    #Aquí se aplica la extracción de características por PCA\n",
    "    #Complete el código\n",
    "    #Complete el código llamando el método extract_features. Tenga en cuenta lo que le pide el ejercicio 3.1\n",
    "    ex = extract_features('pca',21) \n",
    "\n",
    "    #Fit de PCA\n",
    "    #Complete el código con el fit correspondiente\n",
    "    ex = ex.fit(X)\n",
    "    \n",
    "    #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "    #complete el código aquí para hacer la transformación\n",
    "    X_ex = ex.transform(X)\n",
    "    \n",
    "    \n",
    "    #Aquí se aplica la extracción de características por LDA\n",
    "    \n",
    "    #OPCIONAL\n",
    "    '''\n",
    "    ex = #Complete el código llamando el método extract_features. Tenga en cuenta lo que le pide el ejercicio 3.1\n",
    "\n",
    "    #Fit de LDA\n",
    "    ex = #Complete el código con el fit correspondiente\n",
    "    \n",
    "    #Transforme las variables y genere el nuevo espacio de características de menor dimensión\n",
    "    X_ex = #complete el código aquí para hacer la transformación\n",
    "    '''\n",
    "    \n",
    "    #Se aplica CV-10\n",
    "    \n",
    "    X_train, X_test = X_ex[train_index], X_ex[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]  \n",
    "   \n",
    "    #Aquí se entrena y se valida el modelo luego de aplicar extracción de características con PCA o LDA\n",
    "    \n",
    "    ######\n",
    "    \n",
    "    # Entrenamiento el modelo.\n",
    "    model = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Validación del modelo\n",
    "    ypred = model.predict(X_test)\n",
    "    \n",
    "    #######\n",
    "\n",
    "    Errores[j] = classification_error(ypred, y_test)\n",
    "    j+=1\n",
    "        \n",
    "\n",
    "print(\"\\nError de validación aplicando extracción: \" + str(np.mean(Errores)) + \" +/- \" + str(np.std(Errores)))\n",
    "\n",
    "print(\"\\nEficiencia en validación aplicando extracción: \" + str((1-np.mean(Errores))*100) + \"%\" )\n",
    "\n",
    "print (\"\\n\\nTiempo total de ejecución: \" + str(time.time()-tiempo_i) + \" segundos.\")\n",
    "\n",
    "#print str(ypred)\n",
    "#print str(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "3.1 En la celda de código anterior, varíe los parámetros correspondientes al número de componentes principales a tener en cuenta (use 2, 10, 19 y 21 componentes principales) para PCA y complete la siguiente tabla de resultados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Técnica</th>\n",
    "    <th># de componentes principales</th>\n",
    "    <th>Error de validación</th>\n",
    "    <th>IC (std)</th>\n",
    "    <th>Tiempo de ejecución</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>SVM sin extracción</td>\n",
    "    <td>N/A</td>\n",
    "    <td>0.07712817787226504 +/- 0.05442325724156325</td>\n",
    "    <td>N/A</td>\n",
    "    <td>0.9090361595153809</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>SVM + PCA</td>\n",
    "    <td>2</td>\n",
    "    <td>0.22142793870139074 +/- 0.17001475908401714</td>\n",
    "    <td>77.85720612986093%</td>\n",
    "    <td>1.8265130519866943 s</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>SVM + PCA</td>\n",
    "    <td>10</td>\n",
    "    <td>0.09169324120825582 +/- 0.061564467997647386</td>\n",
    "    <td>90.83067587917442%</td>\n",
    "    <td>1.1364219188690186</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>SVM + PCA</td>\n",
    "    <td>19</td>\n",
    "    <td>0.07193949862698203 +/- 0.04841386304281984</td>\n",
    "    <td>92.8060501373018%</td>\n",
    "    <td>1.1248812675476074</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>SVM + PCA</td>\n",
    "    <td>21</td>\n",
    "    <td>0.07430463282841704 +/- 0.04391645244688941</td>\n",
    "    <td>92.5695367171583%</td>\n",
    "    <td>0.9602289199829102</td>\n",
    "  </tr>\n",
    "      \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Analizando los resultados del punto anterior que puede decir de la viabilidad de aplicar PCA para hacer reducción de dimensión en este problema?\n",
    "\n",
    "R/: Tiene buena eficiencia y el costo computacional es muy poco. Con 10 componentes logramos obtener una eficiencia del 90.8% reduciendo la dimencicion a la mitad en tan solo 1.13 segundos. Hay una mejor eficiciencia con con el numero 19 de componentes, es del 92.8% pero no es muy eficiente al reducir la dimesion, tenemos 19 componentes principales(nuevas caracteristicas o proyecciones) y las caracteristicas que se tenian eran 22.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Explique en sus palabras la principal ventaja que tiene LDA sobre PCA para resolver problemas de clasificación.\n",
    "\n",
    "R/: PCA busca las direcciones de proyecciones que son eficientes para manejar los datos, el LDA busca direcciones que son eficientes para discriminación, es decir que permiten una mejor separación de las clases en el espacio de menor dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Explique en sus palabras las diferencias que existen entre los métodos de selección de características y los métodos de extracción de características vistos en el curso.\n",
    "\n",
    "R/: Los metodos de seleccion de caracteristicas se encargan de elegir las caracteristicas mas aportantes al problema probando con diferentes tecnicas, cuanto afecta cada caracteristica o conjutno de caractaristicas a la solucion del problema, mientras que los metodos de extraccion se valen de tranformaciones lineales en busqueda de datos que realmente aporten a la solucion del problema.\n",
    "Cabe notar que mientras en la seleccion de caracterisitcas el conjunto resultado es interpetable ya que es un subconjunto del conjunto principal en la extraccion las caracterisitcas resultados no son interpetables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
